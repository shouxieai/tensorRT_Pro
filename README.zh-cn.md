é˜…è¯»å…¶ä»–è¯­è¨€çš„README.md:[English](README.md), [ç®€ä½“ä¸­æ–‡](README.zh-cn.md).
## æœ€è¿‘çš„é‡è¦æ›´æ–°ï¼š
- ğŸ”¥ dockeré•œåƒå·²ç»å‘å¸ƒï¼Œè¯·ç‚¹å‡»ï¼š https://hub.docker.com/r/hopef/tensorrt-pro
- âš¡tensorRT_Pro_comments_versionæ¨å‡º(å…±åˆ›ç‰ˆ),ä¸ºæ›´å¥½çš„å­¦ä¹ ä½“éªŒåŠ©åŠ›. Repo: https://github.com/Guanbin-Huang/tensorRT_Pro_comments
- ğŸ”¥ [ç®€å•çš„YoloV5/YoloXå®ç°å·²ç»å‘å¸ƒï¼Œç®€å•å¥½ä½¿ï¼Œé«˜æ€§èƒ½ï¼Œåªæœ‰2ä¸ªæ–‡ä»¶å“¦ï¼Œæ²¡æœ‰å¤šä½™ä¾èµ–](simple_yolo)
- ğŸ”¥yolov5-1.0åˆ°6.0/masteræ˜¯æ”¯æŒçš„ï¼Œè¯·çœ‹readmeä¸­å¯¹yolov5æ”¯æŒéƒ¨åˆ†çš„è§£é‡Š
- æ•™ç¨‹çš„ç¬”è®°å’Œä»£ç ä¸‹è½½ï¼š
    - [WarpAffine.lesson.tar.gz](http://zifuture.com:1000/fs/25.shared/warpaffine.lesson.tar.gz)
    - [Offset.tar.gz](http://zifuture.com:1000/fs/25.shared/offset.tar.gz)
- å…³äºCenterNet ä»pytorchåˆ°tensorRTçš„æ¨¡å‹å¯¼å‡ºåˆ°æ¨ç†çš„ä¸­è‹±æ–‡æ•™ç¨‹å·²æ›´æ–°ï¼Œåœ¨tutorial/2.0

## Bç«™åŒæ­¥è§†é¢‘è®²è§£ 
- Bç«™è§†é¢‘è®²è§£ ï¼šhttps://www.bilibili.com/video/BV1Xw411f7FW
- ç›¸å…³PPTXä¸‹è½½ï¼šhttp://zifuture.com:1556/fs/sxai/tensorRT.pptx
- tutorial æ–‡ä»¶å¤¹: ä¸€ä¸ªå¯¹å…¥é—¨è€…æå…¶å‹å¥½çš„æ¡†æ¶æ¦‚è§ˆå’ŒæŒ‡å—


## é«˜æ€§èƒ½æ¨ç†ï¼ŒTensorRT C++/Pythonåº“ï¼Œå·¥ä¸šçº§ï¼Œä¾¿äºä½¿ç”¨

- C++æ¥å£ï¼ŒYoloXä¸‰è¡Œä»£ç 
```C++

// åˆ›å»ºæ¨ç†å¼•æ“åœ¨0æ˜¾å¡ä¸Š
//auto engine = Yolo::create_infer("yolov5m.fp32.trtmodel", Yolo::Type::V5, 0);
auto engine = Yolo::create_infer("yolox_m.fp32.trtmodel", Yolo::Type::X, 0);

// åŠ è½½å›¾åƒ
auto image = cv::imread("1.jpg");

// æ¨ç†å¹¶è·å–ç»“æœ
auto box = engine->commit(image).get();  // å¾—åˆ°çš„æ˜¯vector<Box>
```

- Pythonæ¥å£
```python
import trtpy

model     = models.resnet18(True).eval().to(device)
trt_model = tp.from_torch(model, input)
trt_out   = trt_model(input)
```

- ç®€å•çš„yolo pythonæ¥å£
  ```python
  import os
  import cv2
  import numpy as np
  import trtpy as tp

  engine_file = "yolov5s.fp32.trtmodel"
  if not os.path.exists(engine_file):
      tp.compile_onnx_to_file(1, tp.onnx_hub("yolov5s"), engine_file)

  yolo   = tp.Yolo(engine_file, type=tp.YoloType.V5)
  image  = cv2.imread("car.jpg")
  bboxes = yolo.commit(image).get()
  print(f"{len(bboxes)} objects")

  for box in bboxes:
      left, top, right, bottom = map(int, [box.left, box.top, box.right, box.bottom])
      cv2.rectangle(image, (left, top), (right, bottom), tp.random_color(box.class_label), 5)

  saveto = "yolov5.car.jpg"
  print(f"Save to {saveto}")

  cv2.imwrite(saveto, image)
  cv2.imshow("result", image)
  cv2.waitKey()
  ```


## ç®€ä»‹
1. åŸºäºtensorRT8.0ï¼ŒC++/Pythoné«˜çº§æ¥å£
2. ç®€åŒ–è‡ªå®šä¹‰æ’ä»¶çš„å®ç°è¿‡ç¨‹ï¼Œå°è£…åºåˆ—åŒ–ã€ååºåˆ—åŒ–
3. ç®€åŒ–fp32ã€fp16ã€int8ç¼–è¯‘è¿‡ç¨‹ï¼ŒC++/Pythonéƒ¨ç½²ï¼ŒæœåŠ¡å™¨/åµŒå…¥å¼ä½¿ç”¨
4. é«˜æ€§èƒ½æ‹¿æ¥å°±ç”¨çš„æ¡ˆä¾‹æœ‰RetinaFaceã€Scrfdã€YoloV5ã€YoloXã€Arcfaceã€AlphaPoseã€DeepSORT(C++)


## YoloXå’ŒYoloV5ç³»åˆ—æ‰€æœ‰æ¨¡å‹æ€§èƒ½æµ‹è¯•

<details>
<summary>app_yolo.cppé€Ÿåº¦æµ‹è¯•</summary>

1. è¾“å…¥åˆ†è¾¨ç‡(YoloV5P5ã€YoloX)=(640x640)ï¼Œ(YoloV5P6)=(1280x1280)
2. max batch size = 16
3. å›¾åƒé¢„å¤„ç† + æ¨ç† + åå¤„ç†
4. cuda10.2ï¼Œcudnn8.2.2.26ï¼ŒTensorRT-8.0.1.6
5. RTX2080Ti
6. æµ‹è¯•æ¬¡æ•°ï¼Œ100æ¬¡å–å¹³å‡ï¼Œå»æ‰warmup
7. æµ‹è¯•ç»“æœï¼š[workspace/perf.result.std.log](workspace/perf.result.std.log)
8. æµ‹è¯•ä»£ç ï¼š[src/application/app_yolo.cpp](src/application/app_yolo.cpp)
9. æµ‹è¯•å›¾åƒï¼Œ6å¼ ã€‚ç›®å½•ï¼šworkspace/inference
    - åˆ†è¾¨ç‡åˆ†åˆ«ä¸ºï¼š810x1080ï¼Œ500x806ï¼Œ1024x684ï¼Œ550x676ï¼Œ1280x720ï¼Œ800x533
10. æµ‹è¯•æ–¹å¼ï¼ŒåŠ è½½6å¼ å›¾åï¼Œä»¥åŸå›¾é‡å¤100æ¬¡ä¸åœå¡è¿›å»ã€‚è®©æ¨¡å‹ç»å†å®Œæ•´çš„å›¾åƒçš„é¢„å¤„ç†ï¼Œåå¤„ç†

---

|æ¨¡å‹åç§°|åˆ†è¾¨ç‡|æ¨¡å‹ç±»å‹|ç²¾åº¦|è€—æ—¶|å¸§ç‡|
|---|---|---|---|---|---|
|yolox_x|640x640|YoloX|FP32|21.879 |45.71 |
|yolox_l|640x640|YoloX|FP32|12.308 |81.25 |
|yolox_m|640x640|YoloX|FP32|6.862 |145.72 |
|yolox_s|640x640|YoloX|FP32|3.088 |323.81 |
|yolox_x|640x640|YoloX|FP16|6.763 |147.86 |
|yolox_l|640x640|YoloX|FP16|3.933 |254.25 |
|yolox_m|640x640|YoloX|FP16|2.515 |397.55 |
|yolox_s|640x640|YoloX|FP16|1.362 |734.48 |
|yolox_x|640x640|YoloX|INT8|4.070 |245.68 |
|yolox_l|640x640|YoloX|INT8|2.444 |409.21 |
|yolox_m|640x640|YoloX|INT8|1.730 |577.98 |
|yolox_s|640x640|YoloX|INT8|1.060 |943.15 |
|yolov5x6|1280x1280|YoloV5_P6|FP32|68.022 |14.70 |
|yolov5l6|1280x1280|YoloV5_P6|FP32|37.931 |26.36 |
|yolov5m6|1280x1280|YoloV5_P6|FP32|20.127 |49.69 |
|yolov5s6|1280x1280|YoloV5_P6|FP32|8.715 |114.75 |
|yolov5x|640x640|YoloV5_P5|FP32|18.480 |54.11 |
|yolov5l|640x640|YoloV5_P5|FP32|10.110 |98.91 |
|yolov5m|640x640|YoloV5_P5|FP32|5.639 |177.33 |
|yolov5s|640x640|YoloV5_P5|FP32|2.578 |387.92 |
|yolov5x6|1280x1280|YoloV5_P6|FP16|20.877 |47.90 |
|yolov5l6|1280x1280|YoloV5_P6|FP16|10.960 |91.24 |
|yolov5m6|1280x1280|YoloV5_P6|FP16|7.236 |138.20 |
|yolov5s6|1280x1280|YoloV5_P6|FP16|3.851 |259.68 |
|yolov5x|640x640|YoloV5_P5|FP16|5.933 |168.55 |
|yolov5l|640x640|YoloV5_P5|FP16|3.450 |289.86 |
|yolov5m|640x640|YoloV5_P5|FP16|2.184 |457.90 |
|yolov5s|640x640|YoloV5_P5|FP16|1.307 |765.10 |
|yolov5x6|1280x1280|YoloV5_P6|INT8|12.207 |81.92 |
|yolov5l6|1280x1280|YoloV5_P6|INT8|7.221 |138.49 |
|yolov5m6|1280x1280|YoloV5_P6|INT8|5.248 |190.55 |
|yolov5s6|1280x1280|YoloV5_P6|INT8|3.149 |317.54 |
|yolov5x|640x640|YoloV5_P5|INT8|3.704 |269.97 |
|yolov5l|640x640|YoloV5_P5|INT8|2.255 |443.53 |
|yolov5m|640x640|YoloV5_P5|INT8|1.674 |597.40 |
|yolov5s|640x640|YoloV5_P5|INT8|1.143 |874.91 |

</details>

<details>
<summary>app_yolo_fast.cppé€Ÿåº¦æµ‹è¯•ï¼Œé€Ÿåº¦åªä¼šæ— æ­¢å¢ƒçš„è¿½æ±‚å¿«</summary>

- ç›¸æ¯”ä¸Šé¢ï¼Œæ¨¡å‹å»å¤´å»å°¾ï¼Œå»æ‰äº†Focuså’Œå°¾éƒ¨çš„å¤šä½™çš„transposeç­‰èŠ‚ç‚¹ï¼Œèåˆåˆ°äº†CUDAæ ¸å‡½æ•°ä¸­å®ç°ã€‚å…¶ä»–éƒ½æ˜¯ä¸€æ ·çš„ã€‚æ²¡æœ‰ç²¾åº¦åŒºåˆ«ï¼Œé€Ÿåº¦ä¸Šæå‡å¤§çº¦0.5ms
- æµ‹è¯•ç»“æœï¼š[workspace/perf.result.std.log](workspace/perf.result.std.log)
- æµ‹è¯•ä»£ç ï¼š[src/application/app_yolo_fast.cpp](src/application/app_yolo_fast.cpp)
- å¯ä»¥è‡ªå·±å‚ç…§ä¸‹è½½åçš„onnxåšä¿®æ”¹ï¼Œæˆ–è€…ç¾¤é‡Œæè¦æ±‚è®²ä¸€è®²
- è¿™ä¸ªå·¥ä½œçš„ä¸»è¦ç›®çš„ï¼Œæ˜¯ä¼˜åŒ–å‰åå¤„ç†çš„æ—¶é—´ï¼Œè¿™åœ¨ä»»ä½•æ—¶å€™éƒ½æ˜¯æœ‰ç”¨çš„ã€‚å¦‚æœä½ ç”¨yoloxã€yolov5æ›´å°çš„ç³»åˆ—ï¼Œéƒ½å¯ä»¥è€ƒè™‘è¿™ä¸œè¥¿


|æ¨¡å‹åç§°|åˆ†è¾¨ç‡|æ¨¡å‹ç±»å‹|ç²¾åº¦|è€—æ—¶|å¸§ç‡|
|---|---|---|---|---|---|
|yolox_x_fast|640x640|YoloX|FP32|21.598 |46.30 |
|yolox_l_fast|640x640|YoloX|FP32|12.199 |81.97 |
|yolox_m_fast|640x640|YoloX|FP32|6.819 |146.65 |
|yolox_s_fast|640x640|YoloX|FP32|2.979 |335.73 |
|yolox_x_fast|640x640|YoloX|FP16|6.764 |147.84 |
|yolox_l_fast|640x640|YoloX|FP16|3.866 |258.64 |
|yolox_m_fast|640x640|YoloX|FP16|2.386 |419.16 |
|yolox_s_fast|640x640|YoloX|FP16|1.259 |794.36 |
|yolox_x_fast|640x640|YoloX|INT8|3.918 |255.26 |
|yolox_l_fast|640x640|YoloX|INT8|2.292 |436.38 |
|yolox_m_fast|640x640|YoloX|INT8|1.589 |629.49 |
|yolox_s_fast|640x640|YoloX|INT8|0.954 |1048.47 |
|yolov5x6_fast|1280x1280|YoloV5_P6|FP32|67.075 |14.91 |
|yolov5l6_fast|1280x1280|YoloV5_P6|FP32|37.491 |26.67 |
|yolov5m6_fast|1280x1280|YoloV5_P6|FP32|19.422 |51.49 |
|yolov5s6_fast|1280x1280|YoloV5_P6|FP32|7.900 |126.57 |
|yolov5x_fast|640x640|YoloV5_P5|FP32|18.554 |53.90 |
|yolov5l_fast|640x640|YoloV5_P5|FP32|10.060 |99.41 |
|yolov5m_fast|640x640|YoloV5_P5|FP32|5.500 |181.82 |
|yolov5s_fast|640x640|YoloV5_P5|FP32|2.342 |427.07 |
|yolov5x6_fast|1280x1280|YoloV5_P6|FP16|20.538 |48.69 |
|yolov5l6_fast|1280x1280|YoloV5_P6|FP16|10.404 |96.12 |
|yolov5m6_fast|1280x1280|YoloV5_P6|FP16|6.577 |152.06 |
|yolov5s6_fast|1280x1280|YoloV5_P6|FP16|3.087 |323.99 |
|yolov5x_fast|640x640|YoloV5_P5|FP16|5.919 |168.95 |
|yolov5l_fast|640x640|YoloV5_P5|FP16|3.348 |298.69 |
|yolov5m_fast|640x640|YoloV5_P5|FP16|2.015 |496.34 |
|yolov5s_fast|640x640|YoloV5_P5|FP16|1.087 |919.63 |
|yolov5x6_fast|1280x1280|YoloV5_P6|INT8|11.236 |89.00 |
|yolov5l6_fast|1280x1280|YoloV5_P6|INT8|6.235 |160.38 |
|yolov5m6_fast|1280x1280|YoloV5_P6|INT8|4.311 |231.97 |
|yolov5s6_fast|1280x1280|YoloV5_P6|INT8|2.139 |467.45 |
|yolov5x_fast|640x640|YoloV5_P5|INT8|3.456 |289.37 |
|yolov5l_fast|640x640|YoloV5_P5|INT8|2.019 |495.41 |
|yolov5m_fast|640x640|YoloV5_P5|INT8|1.425 |701.71 |
|yolov5s_fast|640x640|YoloV5_P5|INT8|0.844 |1185.47 |


</details>

## ç¯å¢ƒé…ç½®

<details>
<summary>Linuxä¸‹é…ç½®</summary>


1. æ¨èä½¿ç”¨VSCode
2. åœ¨Makefile/CMakeLists.txtä¸­é…ç½®ä½ çš„cudnnã€cudaã€tensorRT8.0ã€protobufè·¯å¾„
3. é…ç½®Makefileæˆ–è€…CMakeListsä¸­çš„è®¡ç®—èƒ½åŠ›ä¸ºä½ çš„æ˜¾å¡å¯¹åº”å€¼
    - ä¾‹å¦‚`-gencode=arch=compute_75,code=sm_75`ï¼Œä¾‹å¦‚3080Tiæ˜¯86ï¼Œåˆ™æ˜¯ï¼š`-gencode=arch=compute_86,code=sm_86`
    - è®¡ç®—èƒ½åŠ›æ ¹æ®å‹å·å‚è€ƒè¿™é‡ŒæŸ¥çœ‹ï¼šhttps://developer.nvidia.com/zh-cn/cuda-gpus#compute
4. åœ¨.vscode/c_cpp_properties.jsonä¸­é…ç½®ä½ çš„åº“è·¯å¾„
5. CUDAç‰ˆæœ¬ï¼šCUDA10.2
6. CUDNNç‰ˆæœ¬ï¼šcudnn8.2.2.26ï¼Œæ³¨æ„ä¸‹è½½devï¼ˆhæ–‡ä»¶ï¼‰å’Œruntimeï¼ˆsoæ–‡ä»¶ï¼‰
7. tensorRTç‰ˆæœ¬ï¼štensorRT-8.0.1.6-cuda10.2ï¼Œè‹¥è¦ä½¿ç”¨7.xï¼Œè¯·çœ‹ç¯èŠ‚é…ç½®ä¸­çš„ã€ŠTensorRT7.xæ”¯æŒã€‹è¿›è¡Œä¿®æ”¹
8. protobufç‰ˆæœ¬ï¼ˆç”¨äºonnxè§£æå™¨ï¼‰ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯protobufv3.11.4
    - å¦‚æœé‡‡ç”¨å…¶ä»–ç‰ˆæœ¬ï¼Œè¯·å‚è€ƒè¯¥ç« èŠ‚ä¸‹é¢ã€Šé€‚é…Protobufç‰ˆæœ¬ã€‹
    - ä¸‹è½½åœ°å€ï¼šhttps://github.com/protocolbuffers/protobuf/tree/v3.11.4
    - ä¸‹è½½å¹¶ç¼–è¯‘ï¼Œç„¶åä¿®æ”¹Makefileæˆ–è€…CMakeLists.txtçš„è·¯å¾„æŒ‡å‘protobuf3.11.4
- CMake:
    - `mkdir build && cd build`
    - `cmake ..`
    - `make yolo -j8`
- Makefile:
    - `make yolo -j8`

</details>

<details>
<summary>Linuxä¸‹Pythonç¼–è¯‘</summary>

- ç¼–è¯‘å¹¶å®‰è£…:
    - Makefileæ–¹å¼ï¼š
        - åœ¨Makefileä¸­è®¾ç½®`use_python := true`å¯ç”¨pythonæ”¯æŒ
    - CMakeLists.txtæ–¹å¼:
        - åœ¨CMakeLists.txtä¸­ä¿®æ”¹`set(HAS_PYTHON ON)`
    - æ‰§è¡Œç¼–è¯‘`make pyinstall -j8`
    - ç¼–è¯‘åçš„æ–‡ä»¶ï¼Œåœ¨`python/trtpy/libtrtpyc.so`

</details>


<details>
<summary>Windowsä¸‹é…ç½®</summary>

1. ä¾èµ–è¯·æŸ¥çœ‹[lean/README.md](lean/README.md)
2. TensorRT.vcxprojæ–‡ä»¶ä¸­ï¼Œä¿®æ”¹`<Import Project="$(VCTargetsPath)\BuildCustomizations\CUDA 10.0.props" />`ä¸ºä½ é…ç½®çš„CUDAè·¯å¾„
3. TensorRT.vcxprojæ–‡ä»¶ä¸­ï¼Œä¿®æ”¹`<Import Project="$(VCTargetsPath)\BuildCustomizations\CUDA 10.0.targets" />`ä¸ºä½ é…ç½®çš„CUDAè·¯å¾„
4. TensorRT.vcxprojæ–‡ä»¶ä¸­ï¼Œä¿®æ”¹`<CodeGeneration>compute_61,sm_61</CodeGeneration>`ä¸ºä½ æ˜¾å¡é…å¤‡çš„è®¡ç®—èƒ½åŠ›
    - æ ¹æ®å‹å·å‚è€ƒè¿™é‡Œï¼šhttps://developer.nvidia.com/zh-cn/cuda-gpus#compute
5. é…ç½®ä¾èµ–æˆ–è€…ä¸‹è½½ä¾èµ–åˆ°leanä¸­ã€‚é…ç½®VC++ç›®å½•->åŒ…å«ç›®å½•å’Œå¼•ç”¨ç›®å½•
6. é…ç½®ç¯å¢ƒï¼Œè°ƒè¯•->ç¯å¢ƒï¼Œè®¾ç½®PATHè·¯å¾„
7. ç¼–è¯‘å¹¶è¿è¡Œæ¡ˆä¾‹ï¼Œå…¶ä¸­Debugä¸ºè°ƒè¯•ï¼ŒReleaseä¸ºå‘å¸ƒï¼ŒPythonä¸ºtrtpycæ¨¡å—

</details>

<details>
<summary>Windowsä¸‹Pythonç¼–è¯‘</summary>

1. ç¼–è¯‘trtpyc.pydï¼Œåœ¨visual studioä¸­é€‰æ‹©pythonè¿›è¡Œç¼–è¯‘
2. å¤åˆ¶dllï¼Œæ‰§è¡Œpython/copy_dll_to_trtpy.bat
3. åœ¨pythonç›®å½•ä¸‹æ‰§è¡Œæ¡ˆä¾‹ï¼Œpython test_yolov5.py
- å¦‚æœéœ€è¦è¿›è¡Œå®‰è£…ï¼Œåˆ™åœ¨pythonç›®å½•ä¸‹ï¼Œåˆ‡æ¢åˆ°ç›®æ ‡ç¯å¢ƒåï¼Œæ‰§è¡Œ`python setup.py install`ã€‚ï¼ˆæ³¨æ„ï¼Œæ‰§è¡Œäº†1ã€2ä¸¤æ­¥åæ‰è¡Œï¼‰
- ç¼–è¯‘åçš„æ–‡ä»¶ï¼Œåœ¨`python/trtpy/libtrtpyc.pyd`

</details>


<details>
<summary>é€‚é…Protobufç‰ˆæœ¬</summary>

- ä¿®æ”¹onnx/make_pb.shæ–‡ä»¶ä¸­protocç¨‹åºçš„è·¯å¾„`protoc=/data/sxai/lean/protobuf3.11.4/bin/protoc`ï¼ŒæŒ‡å‘ä½ è‡ªå·±ç‰ˆæœ¬çš„protoc

```bash
#åˆ‡æ¢ç»ˆç«¯ç›®å½•åˆ°onnxä¸‹
cd onnx

#æ‰§è¡Œç”Ÿæˆpbæ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨å¤åˆ¶ã€‚ä½¿ç”¨make_pb.shè„šæœ¬
bash make_pb.sh
```

- CMake:
    - ä¿®æ”¹CMakeLists.txtä¸­`set(PROTOBUF_DIR "/data/sxai/lean/protobuf3.11.4")`ä¸ºprotocç›¸åŒçš„è·¯å¾„
```bash
mkdir build && cd build
cmake ..
make yolo -j64
```

- Makefile:
    - ä¿®æ”¹Makefileä¸­`lean_protobuf  := /data/sxai/lean/protobuf3.11.4`ä¸ºprotocçš„ç›¸åŒè·¯å¾„
```bash
make yolo -j64
```


</details>


<details>
<summary>TensorRT7.xæ”¯æŒ</summary>

- é»˜è®¤æ”¯æŒçš„æ˜¯8.x
- CMakeLists.txt/MakeFileä¸­ä¿®æ”¹tensorRTçš„è·¯å¾„
- æ‰§è¡Œ`bash onnx_parser/use_tensorrt_7.x.sh`ï¼Œä¿®æ”¹è§£æå™¨æ”¯æŒä¸º7.x
- æ­£å¸¸è¿›è¡Œç¼–è¯‘è¿è¡Œå³å¯

</details>


<details>
<summary>TensorRT8.xæ”¯æŒ</summary>

- é»˜è®¤æ”¯æŒçš„æ˜¯8.xï¼Œä¸éœ€è¦ä¿®æ”¹
- CMakeLists.txt/MakeFileä¸­ä¿®æ”¹tensorRTçš„è·¯å¾„
- æ‰§è¡Œ`bash onnx_parser/use_tensorrt_8.x.sh`ï¼Œä¿®æ”¹è§£æå™¨æ”¯æŒä¸º8.x
- æ­£å¸¸è¿›è¡Œç¼–è¯‘è¿è¡Œå³å¯

</details>

## å„é¡¹ä»»åŠ¡æ”¯æŒ

<details>
<summary>YoloV5æ”¯æŒ</summary>

- yolov5çš„onnxï¼Œä½ çš„pytorchç‰ˆæœ¬>=1.7æ—¶ï¼Œå¯¼å‡ºçš„onnxæ¨¡å‹å¯ä»¥ç›´æ¥è¢«å½“å‰æ¡†æ¶æ‰€ä½¿ç”¨
- ä½ çš„pytorchç‰ˆæœ¬ä½äº1.7æ—¶ï¼Œæˆ–è€…å¯¹äºyolov5å…¶ä»–ç‰ˆæœ¬ï¼ˆ2.0ã€3.0ã€4.0ï¼‰ï¼Œå¯ä»¥å¯¹opsetè¿›è¡Œç®€å•æ”¹åŠ¨åç›´æ¥è¢«æ¡†æ¶æ‰€æ”¯æŒ
- å¦‚æœä½ æƒ³å®ç°ä½ç‰ˆæœ¬pytorchçš„tensorRTæ¨ç†ã€åŠ¨æ€batchsizeç­‰æ›´å¤šæ›´é«˜çº§çš„é—®é¢˜ï¼Œè¯·æ‰“å¼€æˆ‘ä»¬[åšå®¢åœ°å€](http://zifuture.com:8090)åæ‰¾åˆ°äºŒç»´ç è¿›ç¾¤äº¤æµ
1. ä¸‹è½½yolov5
```bash
git clone git@github.com:ultralytics/yolov5.git
```

2. ä¿®æ”¹ä»£ç ï¼Œä¿è¯åŠ¨æ€batchsize
```python
# yolov5/models/yolo.pyç¬¬55è¡Œï¼Œforwardå‡½æ•° 
# bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
# x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
# ä¿®æ”¹ä¸º:

bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
bs = -1
ny = int(ny)
nx = int(nx)
x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

# yolov5/models/yolo.pyç¬¬70è¡Œ
#  z.append(y.view(bs, -1, self.no))
# ä¿®æ”¹ä¸ºï¼š
z.append(y.view(bs, self.na * ny * nx, self.no))


############# å¯¹äº yolov5-6.0 #####################
# yolov5/models/yolo.pyç¬¬65è¡Œ
# if self.grid[i].shape[2:4] != x[i].shape[2:4] or self.onnx_dynamic:
#    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)
# ä¿®æ”¹ä¸º:
if self.grid[i].shape[2:4] != x[i].shape[2:4] or self.onnx_dynamic:
    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)

# disconnect for pytorch trace
anchor_grid = (self.anchors[i].clone() * self.stride[i]).view(1, -1, 1, 1, 2)

# yolov5/models/yolo.pyç¬¬70è¡Œ
# y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
# ä¿®æ”¹ä¸º:
y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * anchor_grid  # wh

# yolov5/models/yolo.pyç¬¬73è¡Œ
# wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
# ä¿®æ”¹ä¸º:
wh = (y[..., 2:4] * 2) ** 2 * anchor_grid  # wh

############# å¯¹äº yolov5-6.0 #####################


# yolov5/export.pyç¬¬52è¡Œ
#torch.onnx.export(dynamic_axes={'images': {0: 'batch', 2: 'height', 3: 'width'},  # shape(1,3,640,640)
#                                'output': {0: 'batch', 1: 'anchors'}  # shape(1,25200,85)  ä¿®æ”¹ä¸º
torch.onnx.export(dynamic_axes={'images': {0: 'batch'},  # shape(1,3,640,640)
                                'output': {0: 'batch'}  # shape(1,25200,85) 
```


3. å¯¼å‡ºonnxæ¨¡å‹
```bash
cd yolov5
python export.py --weights=yolov5s.pt --dynamic --include=onnx --opset=11
```
4. å¤åˆ¶æ¨¡å‹å¹¶æ‰§è¡Œ
```bash
cp yolov5/yolov5s.onnx tensorRT_cpp/workspace/
cd tensorRT_cpp
make yolo -j32
```

</details>


<details>
<summary>YoloXæ”¯æŒ</summary>

- https://github.com/Megvii-BaseDetection/YOLOX
- ä½ å¯ä»¥é€‰æ‹©ç›´æ¥make runï¼Œä¼šä»é•œåƒåœ°å€ä¸‹è½½onnxå¹¶æ¨ç†è¿è¡Œçœ‹åˆ°æ•ˆæœã€‚ä¸éœ€è¦è‡ªè¡Œå¯¼å‡º
1. ä¸‹è½½YoloX
```bash
git clone git@github.com:Megvii-BaseDetection/YOLOX.git
cd YOLOX
```

2. ä¿®æ”¹ä»£ç 
- è¿™æ˜¯ä¿è¯int8èƒ½å¤Ÿé¡ºåˆ©ç¼–è¯‘å’Œæ€§èƒ½æå‡çš„å…³é”®ï¼Œå¦åˆ™æç¤º`Missing scale and zero-point for tensor (Unnamed Layer* 686)`
- è¿™æ˜¯ä¿è¯æ¨¡å‹æ¨ç†æ­£å¸¸é¡ºåˆ©çš„å…³é”®ï¼Œè™½ç„¶éƒ¨åˆ†æƒ…å†µä¸ä¿®æ”¹ä¹Ÿå¯ä»¥æ‰§è¡Œ
```Python
# yolox/models/yolo_head.pyçš„206è¡Œforwardå‡½æ•°ï¼Œæ›¿æ¢ä¸ºä¸‹é¢ä»£ç 
# self.hw = [x.shape[-2:] for x in outputs]
self.hw = [list(map(int, x.shape[-2:])) for x in outputs]


# yolox/models/yolo_head.pyçš„208è¡Œforwardå‡½æ•°ï¼Œæ›¿æ¢ä¸ºä¸‹é¢ä»£ç 
# [batch, n_anchors_all, 85]
# outputs = torch.cat(
#     [x.flatten(start_dim=2) for x in outputs], dim=2
# ).permute(0, 2, 1)
proc_view = lambda x: x.view(-1, int(x.size(1)), int(x.size(2) * x.size(3)))
outputs = torch.cat(
    [proc_view(x) for x in outputs], dim=2
).permute(0, 2, 1)


# yolox/models/yolo_head.pyçš„253è¡Œdecode_outputså‡½æ•°ï¼Œæ›¿æ¢ä¸ºä¸‹é¢ä»£ç 
#outputs[..., :2] = (outputs[..., :2] + grids) * strides
#outputs[..., 2:4] = torch.exp(outputs[..., 2:4]) * strides
#return outputs
xy = (outputs[..., :2] + grids) * strides
wh = torch.exp(outputs[..., 2:4]) * strides
return torch.cat((xy, wh, outputs[..., 4:]), dim=-1)


# tools/export_onnx.pyçš„77è¡Œ
model.head.decode_in_inference = True
```

3. å¯¼å‡ºonnxæ¨¡å‹
```bash

# ä¸‹è½½æ¨¡å‹ï¼Œæˆ–è®¸ä½ éœ€è¦ç¿»å¢™
# wget https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_m.pth

# å¯¼å‡ºæ¨¡å‹
export PYTHONPATH=$PYTHONPATH:.
python tools/export_onnx.py -c yolox_m.pth -f exps/default/yolox_m.py --output-name=yolox_m.onnx --dynamic --no-onnxsim
```

4. æ‰§è¡Œç¨‹åº
```bash
cp YOLOX/yolox_m.onnx tensorRT_cpp/workspace/
cd tensorRT_cpp
make yolo -j32
```

</details>


<details>
<summary>YoloV3æ”¯æŒ</summary>
  
- yolov3çš„onnxï¼Œä½ çš„pytorchç‰ˆæœ¬>=1.7æ—¶ï¼Œå¯¼å‡ºçš„onnxæ¨¡å‹å¯ä»¥ç›´æ¥è¢«å½“å‰æ¡†æ¶æ‰€ä½¿ç”¨
- ä½ çš„pytorchç‰ˆæœ¬ä½äº1.7æ—¶ï¼Œæˆ–è€…å¯¹äºyolov3ï¼Œå¯ä»¥å¯¹opsetè¿›è¡Œç®€å•æ”¹åŠ¨åç›´æ¥è¢«æ¡†æ¶æ‰€æ”¯æŒ
- å¦‚æœä½ æƒ³å®ç°ä½ç‰ˆæœ¬pytorchçš„tensorRTæ¨ç†ã€åŠ¨æ€batchsizeç­‰æ›´å¤šæ›´é«˜çº§çš„é—®é¢˜ï¼Œè¯·æ‰“å¼€æˆ‘ä»¬[åšå®¢åœ°å€](http://zifuture.com:8090)åæ‰¾åˆ°äºŒç»´ç è¿›ç¾¤äº¤æµ
1. ä¸‹è½½yolov3

```bash
git clone git@github.com:ultralytics/yolov3.git
```

2. ä¿®æ”¹ä»£ç ï¼Œæ”¯æŒåŠ¨æ€batchsizeï¼Œè®©-1æ”¹åˆ°batchä¸Š
```python
# line 55 forward function in yolov3/models/yolo.py 
# bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
# x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
# modified into:

bs, _, ny, nx = map(int, x[i].shape)  # x(bs,255,20,20) to x(bs,3,20,20,85)
bs = -1
x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()


# line 70 in yolov3/models/yolo.py
#  z.append(y.view(bs, -1, self.no))
# modified intoï¼š
z.append(y.view(bs, self.na * ny * nx, self.no))

# line 62 in yolov3/models/yolo.py
# if self.grid[i].shape[2:4] != x[i].shape[2:4] or self.onnx_dynamic:
#    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)
# modified into:
if self.grid[i].shape[2:4] != x[i].shape[2:4] or self.onnx_dynamic:
    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)
anchor_grid = (self.anchors[i].clone() * self.stride[i]).view(1, -1, 1, 1, 2)

# line 70 in yolov3/models/yolo.py
# y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
# modified into:
y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * anchor_grid  # wh

# line 73 in yolov3/models/yolo.py
# wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
# modified into:
wh = (y[..., 2:4] * 2) ** 2 * anchor_grid  # wh


# line 52 in yolov3/export.py
# torch.onnx.export(dynamic_axes={'images': {0: 'batch', 2: 'height', 3: 'width'},  # shape(1,3,640,640)
#                                'output': {0: 'batch', 1: 'anchors'}  # shape(1,25200,85) 
# modified into:
torch.onnx.export(dynamic_axes={'images': {0: 'batch'},  # shape(1,3,640,640)
                                'output': {0: 'batch'}  # shape(1,25200,85) 
```
3. å¯¼å‡ºonnxæ¨¡å‹
```bash
cd yolov3
python export.py --weights=yolov3.pt --dynamic --include=onnx --opset=11
```
4. å¤åˆ¶æ¨¡å‹å¹¶æ‰§è¡Œ
```bash
cp yolov3/yolov3.onnx tensorRT_cpp/workspace/
cd tensorRT_cpp

# ä¿®æ”¹ä»£ç åœ¨ src/application/app_yolo.cpp: mainå‡½æ•°ä¸­ï¼Œä½¿ç”¨V5çš„æ–¹å¼å³å¯è¿è¡Œä»–
# test(Yolo::Type::V3, TRT::Mode::FP32, "yolov3");

make yolo -j32
```

</details>


<details>
<summary>UNet æ”¯æŒ</summary>
  
- è¯·çœ‹è¿™é‡Œçš„ä»£ç : https://github.com/shouxieai/unet-pytorch

```
make dunet -j32
```

</details>


<details>
<summary>Retinafaceæ”¯æŒ</summary>


- https://github.com/biubug6/Pytorch_Retinaface
1. ä¸‹è½½Pytorch_Retinaface
```bash
git clone git@github.com:biubug6/Pytorch_Retinaface.git
cd Pytorch_Retinaface
```

2. ä¸‹è½½æ¨¡å‹ï¼Œè¯·è®¿é—®ï¼šhttps://github.com/biubug6/Pytorch_Retinaface#training çš„trainingèŠ‚ç‚¹æ‰¾åˆ°ä¸‹è½½åœ°å€ï¼Œè§£å‹åˆ°weightsç›®å½•ä¸‹ï¼Œä¸»è¦ç”¨åˆ°mobilenet0.25_Final.pthæ–‡ä»¶
3. ä¿®æ”¹ä»£ç 
```python
# models/retinaface.pyç¬¬24è¡Œï¼Œ
# return out.view(out.shape[0], -1, 2) ä¿®æ”¹ä¸º
return out.view(-1, int(out.size(1) * out.size(2) * 2), 2)

# models/retinaface.pyç¬¬35è¡Œï¼Œ
# return out.view(out.shape[0], -1, 4) ä¿®æ”¹ä¸º
return out.view(-1, int(out.size(1) * out.size(2) * 2), 4)

# models/retinaface.pyç¬¬46è¡Œï¼Œ
# return out.view(out.shape[0], -1, 10) ä¿®æ”¹ä¸º
return out.view(-1, int(out.size(1) * out.size(2) * 2), 10)

# ä»¥ä¸‹æ˜¯ä¿è¯resizeèŠ‚ç‚¹è¾“å‡ºæ˜¯æŒ‰ç…§scaleè€Œéshapeï¼Œä»è€Œè®©åŠ¨æ€å¤§å°å’ŒåŠ¨æ€batchå˜ä¸ºå¯èƒ½
# models/net.pyç¬¬89è¡Œï¼Œ
# up3 = F.interpolate(output3, size=[output2.size(2), output2.size(3)], mode="nearest") ä¿®æ”¹ä¸º
up3 = F.interpolate(output3, scale_factor=2, mode="nearest")

# models/net.pyç¬¬93è¡Œï¼Œ
# up2 = F.interpolate(output2, size=[output1.size(2), output1.size(3)], mode="nearest") ä¿®æ”¹ä¸º
up2 = F.interpolate(output2, scale_factor=2, mode="nearest")

# ä»¥ä¸‹ä»£ç æ˜¯å»æ‰softmaxï¼ˆæŸäº›æ—¶å€™æœ‰bugï¼‰ï¼ŒåŒæ—¶åˆå¹¶è¾“å‡ºä¸ºä¸€ä¸ªï¼Œç®€åŒ–è§£ç éƒ¨åˆ†ä»£ç 
# models/retinaface.pyç¬¬123è¡Œ
# if self.phase == 'train':
#     output = (bbox_regressions, classifications, ldm_regressions)
# else:
#     output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)
# return output
# ä¿®æ”¹ä¸º
output = (bbox_regressions, classifications, ldm_regressions)
return torch.cat(output, dim=-1)

# æ·»åŠ opset_version=11ï¼Œä½¿å¾—ç®—å­æŒ‰ç…§é¢„æœŸå¯¼å‡º
# torch_out = torch.onnx._export(net, inputs, output_onnx, export_params=True, verbose=False,
#     input_names=input_names, output_names=output_names)
torch_out = torch.onnx._export(net, inputs, output_onnx, export_params=True, verbose=False, opset_version=11,
    input_names=input_names, output_names=output_names)
```
4. æ‰§è¡Œå¯¼å‡ºonnx
```bash
python convert_to_onnx.py
```

5. æ‰§è¡Œ
```bash
cp FaceDetector.onnx ../tensorRT_cpp/workspace/mb_retinaface.onnx
cd ../tensorRT_cpp
make retinaface -j64
```

</details>


<details>
<summary>DBFaceæ”¯æŒ</summary>

- https://github.com/dlunion/DBFace

```bash
make dbface -j64
```

</details>


<details>
<summary>Scrfdæ”¯æŒ</summary>

- https://github.com/deepinsight/insightface/tree/master/detection/scrfd
- å…·ä½“å¯¼å‡ºOnnxçš„æ³¨æ„äº‹é¡¹å’Œæ–¹æ³•ï¼Œè¯·åŠ ç¾¤æ²Ÿé€šã€‚ç­‰å¾…åé¢æ›´æ–°

</details>


<details>
<summary>Arcfaceæ”¯æŒ</summary>

- https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch
```C++
auto arcface = Arcface::create_infer("arcface_iresnet50.fp32.trtmodel", 0);
auto feature = arcface->commit(make_tuple(face, landmarks)).get();
cout << feature << endl;  // 1x512
```
- äººè„¸è¯†åˆ«æ¡ˆä¾‹ä¸­ï¼Œ`workspace/face/library`ç›®å½•ä¸ºæ³¨å†Œå…¥åº“äººè„¸
- äººè„¸è¯†åˆ«æ¡ˆä¾‹ä¸­ï¼Œ`workspace/face/recognize`ç›®å½•ä¸ºå¾…è¯†åˆ«çš„ç…§ç‰‡
- ç»“æœå‚¨å­˜åœ¨`workspace/face/result`å’Œ`workspace/face/library_draw`ä¸­

</details>


<details>
<summary>Bertæ–‡æœ¬åˆ†ç±»æ”¯æŒï¼ˆä¸­æ–‡ï¼‰</summary>

- https://github.com/649453932/Bert-Chinese-Text-Classification-Pytorch
- `make bert -j6`  

</details>


## æ¥å£ä»‹ç»

<details>
<summary>Pythonæ¥å£ï¼šä»Pytorchæ¨¡å‹å¯¼å‡ºOnnxå’Œtrtmodel</summary>

- ä½¿ç”¨Pythonæ¥å£å¯ä»¥ä¸€å¥è¯å¯¼å‡ºOnnxå’Œtrtmodelï¼Œä¸€æ¬¡æ€§è°ƒè¯•å‘ç”Ÿçš„é—®é¢˜ï¼Œè§£å†³é—®é¢˜ã€‚å¹¶å‚¨å­˜onnxä¸ºåç»­éƒ¨ç½²ä½¿ç”¨
```python
import trtpy

model = models.resnet18(True).eval()
trtpy.from_torch(
    model, 
    dummy_input, 
    max_batch_size=16, 
    onnx_save_file="test.onnx", 
    engine_save_file="engine.trtmodel"
)
```

</details>

<details>
<summary>Pythonæ¥å£ï¼šTensorRTçš„æ¨ç†</summary>

- YoloXçš„tensorRTæ¨ç†
```python
import trtpy

yolo   = tp.Yolo(engine_file, type=tp.YoloType.X)
image  = cv2.imread("inference/car.jpg")
bboxes = yolo.commit(image).get()
```

- Pytorchçš„æ— ç¼å¯¹æ¥
```python
import trtpy

model     = models.resnet18(True).eval().to(device)
trt_model = tp.from_torch(model, input)
trt_out   = trt_model(input)
```

</details>


<details>
<summary>C++æ¥å£ï¼šYoloXæ¨ç†</summary>

```C++

// åˆ›å»ºæ¨ç†å¼•æ“åœ¨0æ˜¾å¡ä¸Š
auto engine = Yolo::create_infer("yolox_m.fp32.trtmodel"ï¼Œ Yolo::Type::X, 0);

// åŠ è½½å›¾åƒ
auto image = cv::imread("1.jpg");

// æ¨ç†å¹¶è·å–ç»“æœ
auto box = engine->commit(image).get();
```

</details>


<details>
<summary>C++æ¥å£ï¼šç¼–è¯‘æ¨¡å‹FP32/FP16</summary>

```cpp
TRT::compile(
  TRT::Mode::FP32,   // ä½¿ç”¨fp32æ¨¡å‹ç¼–è¯‘
  3,                          // max batch size
  "plugin.onnx",              // onnx æ–‡ä»¶
  "plugin.fp32.trtmodel",     // ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
  {}                         // é‡æ–°å®šåˆ¶è¾“å…¥çš„shape
);
```
- å¯¹äºFP32ç¼–è¯‘ï¼Œåªéœ€è¦æä¾›onnxæ–‡ä»¶å³å¯ï¼Œå¯ä»¥å…è®¸é‡å®šä¹‰onnxè¾“å…¥èŠ‚ç‚¹çš„shape
- å¯¹äºåŠ¨æ€æˆ–è€…é™æ€batchçš„æ”¯æŒï¼Œä»…ä»…åªéœ€è¦ä¸€ä¸ªé€‰é¡¹ï¼Œè¿™å¯¹äºå®˜æ–¹å‘å¸ƒçš„è§£æå™¨æ˜¯ä¸æ”¯æŒçš„

</details>

<details>
<summary>C++æ¥å£ï¼šç¼–è¯‘INT8æ¨¡å‹</summary>

- ä¼—æ‰€å‘¨çŸ¥ï¼Œint8çš„æ¨ç†æ•ˆæœæ¯”fp32ç¨å¾®å·®ä¸€ç‚¹ï¼ˆé¢„è®¡-5%çš„æŸå¤±ï¼‰ï¼Œä½†æ˜¯é€Ÿåº¦ç¡®å¿«å¾ˆå¤šå¾ˆå¤šï¼Œè¿™é‡Œé€šè¿‡é›†æˆçš„ç¼–è¯‘æ–¹å¼ï¼Œå¾ˆå®¹æ˜“å®ç°int8çš„ç¼–è¯‘å·¥ä½œ
```cpp
// å®šä¹‰int8çš„æ ‡å®šæ•°æ®å¤„ç†å‡½æ•°ï¼Œè¯»å–æ•°æ®å¹¶äº¤ç»™tensorçš„å‡½æ•°
auto int8process = [](int current, int count, vector<string>& images, shared_ptr<TRT::Tensor>& tensor){
    for(int i = 0; i < images.size(); ++i){

    // å¯¹äºint8çš„ç¼–è¯‘éœ€è¦è¿›è¡Œæ ‡å®šï¼Œè¿™é‡Œè¯»å–å›¾åƒæ•°æ®å¹¶é€šè¿‡set_norm_matåˆ°tensorä¸­
        auto image = cv::imread(images[i]);
        cv::resize(image, image, cv::Size(640, 640));
        float mean[] = {0, 0, 0};
        float std[]  = {1, 1, 1};
        tensor->set_norm_mat(i, image, mean, std);
    }
};


// ç¼–è¯‘æ¨¡å‹æŒ‡å®šä¸ºINT8
auto model_file = "yolov5m.int8.trtmodel";
TRT::compile(
  TRT::Mode::INT8,            // é€‰æ‹©INT8
  3,                          // max batch size
  "yolov5m.onnx",             // onnxæ–‡ä»¶
  model_file,                 // ç¼–è¯‘åä¿å­˜çš„æ–‡ä»¶
  {},                         // é‡å®šä¹‰è¾“å…¥çš„shape
  int8process,                // æŒ‡å®šint8æ ‡å®šæ•°æ®çš„å¤„ç†å›è°ƒå‡½æ•°
  ".",                        // æŒ‡å®šint8æ ‡å®šå›¾åƒæ•°æ®çš„ç›®å½•
  ""                          // æŒ‡å®šint8æ ‡å®šåçš„æ•°æ®å‚¨å­˜/è¯»å–è·¯å¾„
);
```
- é¿å…äº†å®˜æ–¹æ ‡å®šæµç¨‹åˆ†ç¦»çš„é—®é¢˜ï¼Œå¤æ‚åº¦å¤ªé«˜ï¼Œåœ¨è¿™é‡Œç›´æ¥é›†æˆä¸ºä¸€ä¸ªå‡½æ•°å¤„ç†

</details>


<details>
<summary>C++æ¥å£ï¼šæ¨ç†</summary>

- å¯¹äºæ¨¡å‹æ¨ç†ï¼Œå°è£…äº†Tensorç±»ï¼Œå®ç°æ¨ç†çš„ç»´æŠ¤å’Œæ•°æ®äº¤äº’ï¼Œå¯¹äºæ•°æ®ä»GPUåˆ°CPUè¿‡ç¨‹å®Œå…¨éšè—ç»†èŠ‚
- å°è£…äº†Engineç±»ï¼Œå®ç°æ¨¡å‹æ¨ç†å’Œç®¡ç†
```cpp
// æ¨¡å‹åŠ è½½ï¼Œå¾—åˆ°ä¸€ä¸ªå…±äº«æŒ‡é’ˆï¼Œå¦‚æœä¸ºç©ºè¡¨ç¤ºåŠ è½½å¤±è´¥
auto engine = TRT::load_infer("yolov5m.fp32.trtmodel");

// æ‰“å°æ¨¡å‹ä¿¡æ¯
engine->print();

// åŠ è½½å›¾åƒ
auto image = imread("demo.jpg");

// è·å–æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºtensorèŠ‚ç‚¹ï¼Œå¯ä»¥æ ¹æ®åå­—æˆ–è€…ç´¢å¼•è·å–å…·ä½“ç¬¬å‡ ä¸ª
auto input = engine->input(0);
auto output = engine->output(0);

// æŠŠå›¾åƒå¡åˆ°input tensorä¸­ï¼Œè¿™é‡Œæ˜¯å‡å»å‡å€¼ï¼Œå¹¶é™¤ä»¥æ ‡å‡†å·®
float mean[] = {0, 0, 0};
float std[]  = {1, 1, 1};
input->set_norm_mat(i, image, mean, std);

// æ‰§è¡Œæ¨¡å‹çš„æ¨ç†ï¼Œè¿™é‡Œå¯ä»¥å…è®¸å¼‚æ­¥æˆ–è€…åŒæ­¥
engine->forward();

// è¿™é‡Œæ‹¿åˆ°çš„æŒ‡é’ˆå³æ˜¯æœ€ç»ˆçš„ç»“æœæŒ‡é’ˆï¼Œå¯ä»¥è¿›è¡Œè®¿é—®æ“ä½œ
float* output_ptr = output->cpu<float>();
// è¿™é‡Œå¯¹output_ptrè¿›è¡Œå¤„ç†å³å¯å¾—åˆ°ç»“æœ
```

</details>


<details>
<summary>C++æ¥å£ï¼šæ’ä»¶</summary>

- åªéœ€è¦å®šä¹‰å¿…è¦çš„æ ¸å‡½æ•°å’Œæ¨ç†è¿‡ç¨‹ï¼Œå®Œå…¨éšè—ç»†èŠ‚ï¼Œéšè—æ’ä»¶çš„åºåˆ—åŒ–ã€ååºåˆ—åŒ–ã€æ³¨å…¥
- å¯ä»¥ç®€æ´çš„å®ç°FP32ã€FP16ä¸¤ç§æ ¼å¼æ”¯æŒçš„æ’ä»¶ã€‚å…·ä½“å‚è§ä»£ç HSwish cu/hpp
```cpp
template<>
__global__ void HSwishKernel(float* input, float* output, int edge) {

    KernelPositionBlock;
    float x = input[position];
    float a = x + 3;
    a = a < 0 ? 0 : (a >= 6 ? 6 : a);
    output[position] = x * a / 6;
}

int HSwish::enqueue(const std::vector<GTensor>& inputs, std::vector<GTensor>& outputs, const std::vector<GTensor>& weights, void* workspace, cudaStream_t stream) {

    int count = inputs[0].count();
    auto grid = CUDATools::grid_dims(count);
    auto block = CUDATools::block_dims(count);
    HSwishKernel <<<grid, block, 0, stream >>> (inputs[0].ptr<float>(), outputs[0].ptr<float>(), count);
    return 0;
}


RegisterPlugin(HSwish);
```

</details>


## å…³äº
- æˆ‘ä»¬çš„åšå®¢åœ°å€ï¼š http://www.zifuture.com/
- æˆ‘ä»¬çš„Bç«™åœ°å€ ï¼š https://space.bilibili.com/1413433465
